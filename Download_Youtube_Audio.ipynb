{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbrahamKong/Youtube_Summerizer/blob/main/Download_Youtube_Audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e0bd1f04",
      "metadata": {
        "id": "e0bd1f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e7f5c2-9aeb-4a2a-b189-6f97ef061abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2023.11.17)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.1\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.84.0)\n",
            "Collecting google-api-python-client\n",
            "  Downloading google_api_python_client-2.111.0-py2.py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<1.dev0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.62.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.1.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.11.17)\n",
            "Installing collected packages: google-api-python-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "Successfully installed google-api-python-client-2.111.0\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-f947ma08\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-f947ma08\n",
            "  Resolved https://github.com/openai/whisper.git to commit 8bc8860694949db53c42ba47ddc23786c2e02a8b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801404 sha256=275900385fca1b33f57b67744eea5d1d84dffe3d371763e6367382f073ec6c45\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6adqr_ul/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.2\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [634 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,326 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,305 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,046 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,599 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [39.8 kB]\n",
            "Fetched 6,317 kB in 2s (3,595 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "28 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n",
            "Collecting yt_dlp\n",
            "  Downloading yt_dlp-2023.11.16-py2.py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen (from yt_dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt_dlp)\n",
            "  Downloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets (from yt_dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2023.11.17)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2.0.7)\n",
            "Collecting brotli (from yt_dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt_dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt_dlp) (3.6)\n",
            "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, yt_dlp\n",
            "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.19.0 websockets-12.0 yt_dlp-2023.11.16\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=c83bb7ca9f05647dace70697b7da86cd3f41b83918dde8eb1992a80464c443a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ],
      "source": [
        "# !pip install youtube-transcript-api\n",
        "# !pip install --upgrade google-api-python-client\n",
        "# !pip install openai==0.28\n",
        "\n",
        "# # For Audio to text\n",
        "# # install openai's whisper\n",
        "# !pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "# # update the packages\n",
        "# !sudo apt update && sudo apt install ffmpeg\n",
        "\n",
        "# # For Downloading Youtube Audio\n",
        "# !pip install yt_dlp\n",
        "# !pip install ffmpeg\n",
        "# !mkdir youtubeaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "27237d25",
      "metadata": {
        "id": "27237d25"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Download Youtube WAV\n",
        "from __future__ import unicode_literals\n",
        "import yt_dlp\n",
        "import ffmpeg\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOUTUBE_API_KEY = ''\n",
        "OPENAI_API_KEY = 'sk-'"
      ],
      "metadata": {
        "id": "j2tSAowWkiZ8"
      },
      "id": "j2tSAowWkiZ8",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to extract youtube video ID from the URL"
      ],
      "metadata": {
        "id": "hYpPxTysk6Em"
      },
      "id": "hYpPxTysk6Em"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_video_id_from_url(url):\n",
        "    \"\"\"\n",
        "    Extracts the YouTube video ID from a given URL.\n",
        "    \"\"\"\n",
        "    regex = r\"(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})\"\n",
        "    match = re.search(regex, url)\n",
        "    return match.group(1) if match else None"
      ],
      "metadata": {
        "id": "si7lmMdWk7Hx"
      },
      "id": "si7lmMdWk7Hx",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to fetch the author, title and description of the youtube video"
      ],
      "metadata": {
        "id": "CP75fnXnk8-E"
      },
      "id": "CP75fnXnk8-E"
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "def get_youtube_video_details(url, youtube_api_key):\n",
        "    \"\"\"\n",
        "    Fetches details of a YouTube video given its URL.\n",
        "    \"\"\"\n",
        "    video_id = extract_video_id_from_url(url)\n",
        "\n",
        "    # Initialize YouTube API client\n",
        "    youtube = build('youtube', 'v3', developerKey=youtube_api_key)\n",
        "    request = youtube.videos().list(part=\"snippet\", id=video_id)\n",
        "    response = request.execute()\n",
        "\n",
        "    if 'items' in response and len(response['items']) > 0:\n",
        "        title = response['items'][0]['snippet']['title']\n",
        "        author = response['items'][0]['snippet']['channelTitle']\n",
        "        description = response['items'][0]['snippet']['description']\n",
        "        return title, author, description\n",
        "    else:\n",
        "        return \"Video not found\", \"\", \"\""
      ],
      "metadata": {
        "id": "BTEr2LoJk-J6"
      },
      "id": "BTEr2LoJk-J6",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound\n",
        "\n",
        "def get_video_transcript(video_url):\n",
        "    try:\n",
        "        video_id = extract_video_id_from_url(video_url)\n",
        "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "        # Fetch the transcript in English or the first available transcript\n",
        "        if transcript_list.find_transcript(['en']):\n",
        "            transcript = transcript_list.find_transcript(['en']).fetch()\n",
        "        else:\n",
        "            transcript = transcript_list[0].fetch()\n",
        "\n",
        "        # Combine the text of the transcript\n",
        "        combined_transcript = ' '.join([t['text'] for t in transcript])\n",
        "        return combined_transcript\n",
        "    except NoTranscriptFound:\n",
        "        return \"No transcript found for this video.\""
      ],
      "metadata": {
        "id": "hbaGNaflk_iZ"
      },
      "id": "hbaGNaflk_iZ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to summarize the youtube video using OpenAI API"
      ],
      "metadata": {
        "id": "fgXHHKd2lB7Q"
      },
      "id": "fgXHHKd2lB7Q"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def summarize_text(text, openai_api_key):\n",
        "    \"\"\"\n",
        "    Summarizes the given text using OpenAI's GPT-3.\n",
        "    \"\"\"\n",
        "    openai.api_key = openai_api_key\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Summarize the following text:\\n\\n{text}\"}\n",
        "        ],\n",
        "        max_tokens=1500\n",
        "    )\n",
        "\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "def split_text_into_chunks(text, chunk_size=4000):\n",
        "    \"\"\"\n",
        "    Splits text into smaller chunks, each with a maximum of chunk_size characters.\n",
        "    \"\"\"\n",
        "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "def summarize_large_text(text, openai_api_key):\n",
        "    \"\"\"\n",
        "    Splits a large text into chunks and summarizes each chunk.\n",
        "    \"\"\"\n",
        "    chunks = split_text_into_chunks(text)\n",
        "    summaries = [summarize_text(chunk, openai_api_key) for chunk in chunks]\n",
        "    return ' '.join(summaries)\n",
        "\n"
      ],
      "metadata": {
        "id": "YwHk7HB1lF9Q"
      },
      "id": "YwHk7HB1lF9Q",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to download youtube audio"
      ],
      "metadata": {
        "id": "XzYok5m0lHsE"
      },
      "id": "XzYok5m0lHsE"
    },
    {
      "cell_type": "code",
      "source": [
        "def download_youtube_audio(title, url):\n",
        "  # Download options\n",
        "  ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'wav',\n",
        "    }],\n",
        "    \"outtmpl\": f'youtubeaudio/{title}',  # Output template\n",
        "  }\n",
        "\n",
        "  # Function to download from URL\n",
        "  with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "      ydl.download([url])"
      ],
      "metadata": {
        "id": "s6yJFkBvXbat"
      },
      "id": "s6yJFkBvXbat",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the audio to speech-to-text"
      ],
      "metadata": {
        "id": "Y2EXqVwzlTRs"
      },
      "id": "Y2EXqVwzlTRs"
    },
    {
      "cell_type": "code",
      "source": [
        "def speech_to_text(AUDIO_PATH):\n",
        "  # Run Whisper AI:\n",
        "  !whisper {AUDIO_PATH} --model medium\n",
        "\n",
        "  # Additional arguments:\n",
        "  !whisper -h"
      ],
      "metadata": {
        "id": "7SfSl3SxlUsZ"
      },
      "id": "7SfSl3SxlUsZ",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_transcript(url):\n",
        "  # Grab Youtube title to name the audio file\n",
        "  title, author, description = get_youtube_video_details(url, YOUTUBE_API_KEY)\n",
        "  AUDIO_NAME = title.replace(\" \", \"_\")\n",
        "\n",
        "  download_youtube_audio(AUDIO_NAME, url)\n",
        "\n",
        "  audio_path = ('/content/youtubeaudio/' + AUDIO_NAME + \".wav\")\n",
        "  # print(\"AUDIOPATH IS \" + audio_path)\n",
        "\n",
        "  speech_to_text(audio_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "AwYpN878mj19"
      },
      "id": "AwYpN878mj19",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "\n",
        "Youtube_url = \"https://youtu.be/HKoOBiAaHGg'\"\n",
        "\n",
        "generate_transcript(Youtube_url)"
      ],
      "metadata": {
        "id": "CBf63ZvMnEPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed67613a-0d35-4210-9dc7-7cd4b2d63831"
      },
      "id": "CBf63ZvMnEPg",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/HKoOBiAaHGg'\n",
            "[youtube] HKoOBiAaHGg: Downloading webpage\n",
            "[youtube] HKoOBiAaHGg: Downloading ios player API JSON\n",
            "[youtube] HKoOBiAaHGg: Downloading android player API JSON\n",
            "[youtube] HKoOBiAaHGg: Downloading player d23221b6\n",
            "[youtube] HKoOBiAaHGg: Downloading m3u8 information\n",
            "[info] HKoOBiAaHGg: Downloading 1 format(s): 251\n",
            "[download] Destination: youtubeaudio/How_to_Deploy_Your_App_to_Streamlit_Community_Cloud\n",
            "[download] 100% of    9.29MiB in 00:00:00 at 17.78MiB/s  \n",
            "[ExtractAudio] Destination: youtubeaudio/How_to_Deploy_Your_App_to_Streamlit_Community_Cloud.wav\n",
            "Deleting original file youtubeaudio/How_to_Deploy_Your_App_to_Streamlit_Community_Cloud (pass -k to keep)\n",
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:39<00:00, 39.1MiB/s]\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:04.640]  So you have just created your Streamlit application, but you don't want to keep it to yourself\n",
            "[00:04.640 --> 00:07.640]  because you want to share your awesome creation with the world.\n",
            "[00:07.640 --> 00:11.880]  So in this video, I'm going to show you how you could deploy your Streamlit app to the\n",
            "[00:11.880 --> 00:15.240]  Streamlit Community Cloud, and best of all, it's for free.\n",
            "[00:15.240 --> 00:18.160]  So if this sounds like fun, then this video is for you.\n",
            "[00:18.160 --> 00:22.680]  And without further ado, we're starting right now.\n",
            "[00:22.680 --> 00:26.280]  Let's have a look at some of the contents that we're going to be covering today.\n",
            "[00:26.280 --> 00:31.160]  I'm going to show you a five-step process where you could go from step one, building\n",
            "[00:31.160 --> 00:36.760]  a Streamlit app, step two, setting up a Streamlit Community Cloud account, step three, connect\n",
            "[00:36.760 --> 00:42.160]  your GitHub account to the Community Cloud, step four, create a GitHub repo with your\n",
            "[00:42.160 --> 00:48.240]  app, and step five, deploy your Streamlit app to the Community Cloud in just a few clicks.\n",
            "[00:48.240 --> 00:53.880]  So before showing you how to actually deploy your app, let's take a short moment to consider\n",
            "[00:53.880 --> 00:59.280]  the high-level overview of why do you need to deploy your Streamlit app to the cloud.\n",
            "[00:59.280 --> 01:04.160]  So obviously, the most important reason is that you want to share your creation with\n",
            "[01:04.160 --> 01:10.000]  the entire world to see, to make use of, or perhaps to give you comments, feedbacks, and\n",
            "[01:10.000 --> 01:11.320]  points for improvement.\n",
            "[01:11.320 --> 01:15.820]  And best of all, anyone in the world could have access to your app without installing\n",
            "[01:15.820 --> 01:20.960]  any prerequisite Python libraries, as they are able to access the functionality of the\n",
            "[01:20.960 --> 01:23.120]  app right inside their browser.\n",
            "[01:23.120 --> 01:27.800]  So in a nutshell, you have generally two options for deploying your Streamlit app.\n",
            "[01:27.800 --> 01:32.160]  The first one is to manually set up your virtual private server and then configure everything\n",
            "[01:32.160 --> 01:35.360]  so that it works together and your app is hosted.\n",
            "[01:35.360 --> 01:40.320]  Option number two is to use a cloud platform where essentially you could upload your app\n",
            "[01:40.320 --> 01:45.880]  repo onto the GitHub and then connect it to the cloud platform so that it could be hosted.\n",
            "[01:45.880 --> 01:48.780]  And so in this video, we're going to cover the second approach.\n",
            "[01:48.780 --> 01:53.460]  And the reason being is that it's the simplest approach and it will allow you to get up and\n",
            "[01:53.460 --> 01:54.860]  running in no time.\n",
            "[01:54.860 --> 01:58.960]  And of course, the first option where you could create your own private server provides\n",
            "[01:58.960 --> 02:03.780]  you with full control, but then the time and cost involved in setting up the platform would\n",
            "[02:03.780 --> 02:07.140]  require a hefty investment of time and cost.\n",
            "[02:07.140 --> 02:12.460]  So here are some of the reasons why you want to deploy your Streamlit app to the Streamlit\n",
            "[02:12.460 --> 02:13.460]  Community Cloud.\n",
            "[02:13.460 --> 02:15.660]  So the first advantage is that it's free.\n",
            "[02:15.660 --> 02:18.700]  You could deploy your Streamlit apps at no charge.\n",
            "[02:18.700 --> 02:22.820]  Advantage number two, you could deploy it in a few clicks and your fully hosted app\n",
            "[02:22.820 --> 02:25.220]  will be shareable in a few minutes.\n",
            "[02:25.220 --> 02:29.620]  Third advantage is that all of your code is on the cloud in the GitHub repo and this allows\n",
            "[02:29.620 --> 02:31.980]  you to collaborate with your peers.\n",
            "[02:31.980 --> 02:36.060]  Fourth advantage is that it supports live updates to your code so that whenever you\n",
            "[02:36.060 --> 02:40.940]  push a new code change, your Streamlit app will be updated in real time.\n",
            "[02:40.940 --> 02:44.620]  Advantage number five is that you'll be able to securely connect to your data where you\n",
            "[02:44.620 --> 02:48.860]  could connect to all of your data sources using secure protocols.\n",
            "[02:48.860 --> 02:54.140]  Advantage number six, you could restrict access to apps, though by default you'll have access\n",
            "[02:54.140 --> 02:59.220]  to one private app that will allow you to create an app that is not yet ready for the\n",
            "[02:59.220 --> 03:02.340]  public and when it's ready, you could make it public.\n",
            "[03:02.340 --> 03:07.500]  Advantage number seven, you could easily manage all of your Streamlit apps in one control\n",
            "[03:07.500 --> 03:12.420]  center, which will allow you to collaborate with your peers, name or rename your Streamlit\n",
            "[03:12.420 --> 03:16.660]  apps and just generally have a glance in one view all of the apps that you have just\n",
            "[03:16.660 --> 03:17.660]  created.\n",
            "[03:17.660 --> 03:23.660]  All right, and so the first step is to create your Streamlit app and so I'm going to launch\n",
            "[03:23.660 --> 03:31.780]  the Atom IDE on my computer or you could use any other code editor as well.\n",
            "[03:31.780 --> 03:33.580]  So let's create a simple app.\n",
            "[03:33.580 --> 03:43.420]  We're going to import Streamlit as st, then we're going to say st.write and then I'm going\n",
            "[03:43.420 --> 03:53.660]  to say hello world and then we're going to save it.\n",
            "[03:53.660 --> 03:55.060]  We're going to save it to the desktop.\n",
            "[03:55.060 --> 03:59.260]  I'll call it Streamlit app.py.\n",
            "[03:59.500 --> 04:09.020]  So the next step is I'll set up an account on this Streamlit community cloud.\n",
            "[04:09.020 --> 04:20.140]  You could go to streamlit.io slash cloud and then you can see here that all of the high\n",
            "[04:20.140 --> 04:26.660]  level overview is provided here on this web page and you could go ahead and click on sign\n",
            "[04:26.740 --> 04:32.420]  up.\n",
            "[04:32.420 --> 04:39.020]  So you could sign up by continuing by using your Google credentials or your GitHub credentials\n",
            "[04:39.020 --> 04:44.100]  as well or you could also sign up using the traditional approach of putting in your email.\n",
            "[04:44.100 --> 04:51.580]  So let me use my GitHub account.\n",
            "[04:51.700 --> 05:01.500]  So here you put in your GitHub username and then your password and so when you're logging\n",
            "[05:01.500 --> 05:05.260]  in for the first time it's going to ask you for permission.\n",
            "[05:05.260 --> 05:09.740]  So you could authorize Streamlit to have access to your GitHub repo.\n",
            "[05:09.740 --> 05:15.940]  So click on authorize Streamlit and wait just a moment so that you'll be able to deploy\n",
            "[05:15.940 --> 05:21.860]  your app directly from GitHub and click again authorize Streamlit.\n",
            "[05:21.860 --> 05:27.380]  Alright and so you're logged in to the community cloud and because you haven't yet deployed\n",
            "[05:27.380 --> 05:30.980]  your app you're going to see an empty yellow box here.\n",
            "[05:30.980 --> 05:34.980]  So you could go ahead and deploy your first app by clicking new app if you already have\n",
            "[05:34.980 --> 05:40.300]  a GitHub repo but we haven't yet built one so I'm going to show you in just a moment.\n",
            "[05:40.300 --> 05:48.780]  So why don't you go ahead and click on settings and then go to here in the source control\n",
            "[05:48.780 --> 05:54.020]  I am logged in as coding professor using GitHub and so you can see here that you are allocated\n",
            "[05:54.020 --> 06:00.380]  one gigabyte per app and you are able to create one private app and you're also able to create\n",
            "[06:00.380 --> 06:06.140]  an unlimited number of public apps and these are some of the support information just in\n",
            "[06:06.140 --> 06:11.060]  case you have any questions or need help you could check out the documentations and also\n",
            "[06:11.060 --> 06:16.540]  the forums and this board so you can see that because we're logging in using our GitHub\n",
            "[06:16.540 --> 06:21.220]  account the Streamlit community cloud already have access to your GitHub repos and so you\n",
            "[06:21.220 --> 06:23.660]  don't need to do any configuration here.\n",
            "[06:23.660 --> 06:29.860]  However if you have signed up using your Google account then you have to also provide authorization\n",
            "[06:29.860 --> 06:35.100]  for your GitHub account as well and it's as simple as clicking on the link here and then\n",
            "[06:35.100 --> 06:39.300]  providing authorization similar to the one that I've just shown you in just a few moments\n",
            "[06:39.300 --> 06:40.300]  ago.\n",
            "[06:40.300 --> 06:44.980]  Alright so now that we have already connected our GitHub to the Streamlit community cloud\n",
            "[06:44.980 --> 06:50.220]  the next step here step number four is to create a GitHub repo for your Streamlit app\n",
            "[06:50.220 --> 06:58.180]  so let's go ahead and go to GitHub and I have already created a repo app here but I'm going\n",
            "[06:58.580 --> 07:08.540]  a new one to show you go ahead and click on new and let me see I'll say hello app and\n",
            "[07:08.540 --> 07:15.860]  I'll make it public and I'll tick on adding a readme file and then you could click on\n",
            "[07:15.860 --> 07:27.100]  the create repository alright and now you could just click on add file create new file\n",
            "[07:27.100 --> 07:37.860]  and then you want to type in Streamlit app.py and then for the contents here you could copy\n",
            "[07:37.860 --> 07:45.100]  and then paste it here or you could also upload the file to your GitHub repo as well and uploading\n",
            "[07:45.100 --> 07:52.300]  is as simple as clicking here in the add file and clicking upload files and then you could\n",
            "[07:52.300 --> 07:59.620]  just drag and drop the file or you could select it from here and then select the file\n",
            "[07:59.620 --> 08:06.460]  and then open because I have already created the file then I'll just skip this part because\n",
            "[08:06.460 --> 08:13.620]  we already have this Streamlit app.py file and let's do a double check click on the file\n",
            "[08:13.620 --> 08:18.140]  and then here we have a very simple app that will write out the hello world statement on\n",
            "[08:18.140 --> 08:26.060]  your app alright so let's deploy the app here and so this is step number five we're going to\n",
            "[08:26.060 --> 08:30.740]  deploy your Streamlit app to the Streamlit community cloud so go ahead and click on new\n",
            "[08:30.740 --> 08:39.620]  app and then in the repository drop-down menu here you want to click on it and then click on\n",
            "[08:40.380 --> 08:52.020]  the repo that we have just created and then the branch here is main because it is main here as\n",
            "[08:52.020 --> 09:05.740]  well and then the name of the file is Streamlit app.py and go ahead and click on deploy and so\n",
            "[09:05.740 --> 09:11.500]  allow a few moments for the app to be deployed on the server and you'll notice here that this\n",
            "[09:11.500 --> 09:17.340]  is the URL that the server has created for you and if you would like to have a shorter version\n",
            "[09:17.340 --> 09:24.540]  of the app name you could go and rename the app so I'll show you in just a moment let's wait for\n",
            "[09:24.540 --> 09:28.980]  the app to be deployed first in the meantime you could click on the manage app and you'll be able\n",
            "[09:29.060 --> 09:37.900]  to see the log so just in case if there's any error you will be able to see in here you can see\n",
            "[09:37.900 --> 09:43.820]  here that it has already done all of the installation of the prerequisite libraries in order to create\n",
            "[09:43.820 --> 09:49.820]  the server so this server is created just for you on the fly and so when you have clicked on the\n",
            "[09:49.820 --> 09:55.660]  deploy button this particular server has been instantiated and created just for you and so\n",
            "[09:55.660 --> 10:00.340]  there you go you see on the left hand side that your app is already deployed to the Streamlit\n",
            "[10:00.340 --> 10:05.900]  community cloud and you can see the statement hello world all right and so as promised I'm\n",
            "[10:05.900 --> 10:11.460]  going to show you how you could rename your Streamlit app so go ahead and go back to your\n",
            "[10:11.460 --> 10:19.580]  control center of the community cloud you could just type in share.streamlit.io all right and so\n",
            "[10:19.580 --> 10:25.300]  this is the app that you have just deployed hello app and if you click on it you're going\n",
            "[10:25.300 --> 10:32.700]  to go to the app that was just launched a few moments ago and so in this button here you want\n",
            "[10:32.700 --> 10:39.020]  to click on it go and click on settings and here you could rename it you could rename it to hello\n",
            "[10:39.020 --> 10:58.020]  app it has already been taken how about hello app here how about coding hello save it and now\n",
            "[10:58.020 --> 11:06.900]  your app will be available at coding-hello.streamlit.app see it's coding-hello.streamlit.app\n",
            "[11:09.020 --> 11:17.220]  so congratulations you've deployed your first Streamlit app to the cloud using the Streamlit\n",
            "[11:17.220 --> 11:22.700]  community cloud if you found the video helpful don't forget to like and subscribe and also\n",
            "[11:22.700 --> 11:27.100]  turn on notifications and I'll see you in the next video happy streamliting\n",
            "usage: whisper [-h] [--model MODEL] [--model_dir MODEL_DIR] [--device DEVICE]\n",
            "               [--output_dir OUTPUT_DIR] [--output_format {txt,vtt,srt,tsv,json,all}]\n",
            "               [--verbose VERBOSE] [--task {transcribe,translate}]\n",
            "               [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
            "               [--temperature TEMPERATURE] [--best_of BEST_OF] [--beam_size BEAM_SIZE]\n",
            "               [--patience PATIENCE] [--length_penalty LENGTH_PENALTY]\n",
            "               [--suppress_tokens SUPPRESS_TOKENS] [--initial_prompt INITIAL_PROMPT]\n",
            "               [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT] [--fp16 FP16]\n",
            "               [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
            "               [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
            "               [--logprob_threshold LOGPROB_THRESHOLD] [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
            "               [--word_timestamps WORD_TIMESTAMPS] [--prepend_punctuations PREPEND_PUNCTUATIONS]\n",
            "               [--append_punctuations APPEND_PUNCTUATIONS] [--highlight_words HIGHLIGHT_WORDS]\n",
            "               [--max_line_width MAX_LINE_WIDTH] [--max_line_count MAX_LINE_COUNT]\n",
            "               [--max_words_per_line MAX_WORDS_PER_LINE] [--threads THREADS]\n",
            "               audio [audio ...]\n",
            "\n",
            "positional arguments:\n",
            "  audio                 audio file(s) to transcribe\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model MODEL         name of the Whisper model to use (default: small)\n",
            "  --model_dir MODEL_DIR\n",
            "                        the path to save model files; uses ~/.cache/whisper by default (default:\n",
            "                        None)\n",
            "  --device DEVICE       device to use for PyTorch inference (default: cuda)\n",
            "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
            "                        directory to save the outputs (default: .)\n",
            "  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n",
            "                        format of the output file; if not specified, all available formats will be\n",
            "                        produced (default: all)\n",
            "  --verbose VERBOSE     whether to print out the progress and debug messages (default: True)\n",
            "  --task {transcribe,translate}\n",
            "                        whether to perform X->X speech recognition ('transcribe') or X->English\n",
            "                        translation ('translate') (default: transcribe)\n",
            "  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n",
            "                        language spoken in the audio, specify None to perform language detection\n",
            "                        (default: None)\n",
            "  --temperature TEMPERATURE\n",
            "                        temperature to use for sampling (default: 0)\n",
            "  --best_of BEST_OF     number of candidates when sampling with non-zero temperature (default: 5)\n",
            "  --beam_size BEAM_SIZE\n",
            "                        number of beams in beam search, only applicable when temperature is zero\n",
            "                        (default: 5)\n",
            "  --patience PATIENCE   optional patience value to use in beam decoding, as in\n",
            "                        https://arxiv.org/abs/2204.05424, the default (1.0) is equivalent to\n",
            "                        conventional beam search (default: None)\n",
            "  --length_penalty LENGTH_PENALTY\n",
            "                        optional token length penalty coefficient (alpha) as in\n",
            "                        https://arxiv.org/abs/1609.08144, uses simple length normalization by\n",
            "                        default (default: None)\n",
            "  --suppress_tokens SUPPRESS_TOKENS\n",
            "                        comma-separated list of token ids to suppress during sampling; '-1' will\n",
            "                        suppress most special characters except common punctuations (default: -1)\n",
            "  --initial_prompt INITIAL_PROMPT\n",
            "                        optional text to provide as a prompt for the first window. (default: None)\n",
            "  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n",
            "                        if True, provide the previous output of the model as a prompt for the next\n",
            "                        window; disabling may make the text inconsistent across windows, but the\n",
            "                        model becomes less prone to getting stuck in a failure loop (default:\n",
            "                        True)\n",
            "  --fp16 FP16           whether to perform inference in fp16; True by default (default: True)\n",
            "  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n",
            "                        temperature to increase when falling back when the decoding fails to meet\n",
            "                        either of the thresholds below (default: 0.2)\n",
            "  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n",
            "                        if the gzip compression ratio is higher than this value, treat the\n",
            "                        decoding as failed (default: 2.4)\n",
            "  --logprob_threshold LOGPROB_THRESHOLD\n",
            "                        if the average log probability is lower than this value, treat the\n",
            "                        decoding as failed (default: -1.0)\n",
            "  --no_speech_threshold NO_SPEECH_THRESHOLD\n",
            "                        if the probability of the <|nospeech|> token is higher than this value AND\n",
            "                        the decoding has failed due to `logprob_threshold`, consider the segment\n",
            "                        as silence (default: 0.6)\n",
            "  --word_timestamps WORD_TIMESTAMPS\n",
            "                        (experimental) extract word-level timestamps and refine the results based\n",
            "                        on them (default: False)\n",
            "  --prepend_punctuations PREPEND_PUNCTUATIONS\n",
            "                        if word_timestamps is True, merge these punctuation symbols with the next\n",
            "                        word (default: \"'“¿([{-)\n",
            "  --append_punctuations APPEND_PUNCTUATIONS\n",
            "                        if word_timestamps is True, merge these punctuation symbols with the\n",
            "                        previous word (default: \"'.。,，!！?？:：”)]}、)\n",
            "  --highlight_words HIGHLIGHT_WORDS\n",
            "                        (requires --word_timestamps True) underline each word as it is spoken in\n",
            "                        srt and vtt (default: False)\n",
            "  --max_line_width MAX_LINE_WIDTH\n",
            "                        (requires --word_timestamps True) the maximum number of characters in a\n",
            "                        line before breaking the line (default: None)\n",
            "  --max_line_count MAX_LINE_COUNT\n",
            "                        (requires --word_timestamps True) the maximum number of lines in a segment\n",
            "                        (default: None)\n",
            "  --max_words_per_line MAX_WORDS_PER_LINE\n",
            "                        (requires --word_timestamps True, no effect with --max_line_width) the\n",
            "                        maximum number of words in a segment (default: None)\n",
            "  --threads THREADS     number of threads used by torch for CPU inference; supercedes\n",
            "                        MKL_NUM_THREADS/OMP_NUM_THREADS (default: 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "\n",
        "Youtube_url = \"https://youtu.be/qijcT0LnqdU\"\n",
        "\n",
        "generate_transcript(Youtube_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfStfl2XmSgU",
        "outputId": "0dd34720-56d1-40d3-d13d-d27b310c2217"
      },
      "id": "QfStfl2XmSgU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/qijcT0LnqdU\n",
            "[youtube] qijcT0LnqdU: Downloading webpage\n",
            "[youtube] qijcT0LnqdU: Downloading ios player API JSON\n",
            "[youtube] qijcT0LnqdU: Downloading android player API JSON\n",
            "[youtube] qijcT0LnqdU: Downloading m3u8 information\n",
            "[info] qijcT0LnqdU: Downloading 1 format(s): 251\n",
            "[download] Destination: youtubeaudio/看《首爾之春》氣到要測心跳？韓年輕世代起「心率挑戰」運動！這個影響韓國近代史的重大事件是什麼？_【TODAY_看世界】\n",
            "[download] 100% of    8.14MiB in 00:00:00 at 22.51MiB/s  \n",
            "[ExtractAudio] Destination: youtubeaudio/看《首爾之春》氣到要測心跳？韓年輕世代起「心率挑戰」運動！這個影響韓國近代史的重大事件是什麼？_【TODAY_看世界】.wav\n",
            "Deleting original file youtubeaudio/看《首爾之春》氣到要測心跳？韓年輕世代起「心率挑戰」運動！這個影響韓國近代史的重大事件是什麼？_【TODAY_看世界】 (pass -k to keep)\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Chinese\n",
            "[00:00.000 --> 00:02.200] 你最近一次去電影院看電影\n",
            "[00:02.200 --> 00:03.300] 是什麼時候\n",
            "[00:03.300 --> 00:04.600] 這幾年因為疫情\n",
            "[00:04.600 --> 00:06.800] 加上影音串流平台的興起\n",
            "[00:06.800 --> 00:09.300] 願意去電影院的人越來越少了\n",
            "[00:09.300 --> 00:10.300] 韓國也差不多\n",
            "[00:10.300 --> 00:11.700] 但最近有一部叫做\n",
            "[00:11.700 --> 00:13.900] 《一二一二首爾之春》的電影\n",
            "[00:13.900 --> 00:16.100] 卻在韓國掀起了風潮\n",
            "[00:16.100 --> 00:18.500] 上映12天就損一兩評\n",
            "[00:18.500 --> 00:21.300] 突破了465萬觀看人次\n",
            "[00:21.300 --> 00:23.700] 在韓國是叫好又叫做啊\n",
            "[00:23.700 --> 00:25.700] 這部電影講述了被稱為\n",
            "[00:25.700 --> 00:28.500] 光州屠夫的前總統權斗煥\n",
            "[00:28.600 --> 00:30.900] 在1979 12月12日\n",
            "[00:30.900 --> 00:33.100] 發起軍事政變的故事\n",
            "[00:33.100 --> 00:35.000] 權斗煥之前的故事我們提過\n",
            "[00:35.000 --> 00:36.600] 有興趣的可以去看看\n",
            "[00:36.600 --> 00:38.400] 這段歷史對韓國人來講\n",
            "[00:38.400 --> 00:41.100] 重要性好比台灣的二二八事件\n",
            "[00:41.100 --> 00:42.800] 大人是親身經歷\n",
            "[00:42.800 --> 00:44.900] 年輕人則是課本上讀過\n",
            "[00:44.900 --> 00:47.000] 但明知道歷史是這麼發生的\n",
            "[00:47.000 --> 00:49.200] 看電影的時候大家還是很生氣\n",
            "[00:49.200 --> 00:50.500] 韓國的年輕族群\n",
            "[00:50.500 --> 00:53.100] 還發起了心律挑戰運動\n",
            "[00:53.100 --> 00:55.300] 用智慧手錶量心跳數\n",
            "[00:55.300 --> 00:56.900] 看自己有多生氣\n",
            "[00:56.900 --> 00:58.400] 看電影還要量心跳\n",
            "[00:58.400 --> 01:00.000] 看自己的情緒有多激動\n",
            "[01:00.000 --> 01:01.500] 會不會太誇張了\n",
            "[01:01.500 --> 01:03.300] 這個影響韓國近代史的\n",
            "[01:03.300 --> 01:05.000] 重大事件是什麼\n",
            "[01:05.000 --> 01:07.300] 為什麼會讓以此題材的電影\n",
            "[01:07.300 --> 01:08.200] 這麼賣座呢\n",
            "[01:14.200 --> 01:15.100] 大家好 我是Fancy Fe\n",
            "[01:15.100 --> 01:15.900] 歡迎收看 Fancy Fe的\n",
            "[01:15.900 --> 01:17.500]  Today 看世界\n",
            "[01:17.500 --> 01:19.600] 這部電影會在台灣上演\n",
            "[01:19.600 --> 01:21.300] 但講的是歷史事件\n",
            "[01:21.300 --> 01:23.100] 應該沒有劇透的問題吧\n",
            "[01:23.100 --> 01:25.100] 1979年10月26日\n",
            "[01:25.100 --> 01:28.000] 韓國時任獨裁總統普政熙\n",
            "[01:28.000 --> 01:30.400] 被親信金載龜槍殺之後\n",
            "[01:30.400 --> 01:33.400] 人們都以為獨裁統治中要結束\n",
            "[01:33.400 --> 01:35.200] 民主之春要來了\n",
            "[01:35.200 --> 01:36.600] 但是普政熙的死\n",
            "[01:36.600 --> 01:38.200] 留下了權力真空\n",
            "[01:38.200 --> 01:40.600] 當時擔任國軍保安司令官的\n",
            "[01:40.600 --> 01:41.600] 權斗患\n",
            "[01:41.600 --> 01:43.300] 身兼調查刺殺案的\n",
            "[01:43.300 --> 01:44.900] 聯合搜查本部長\n",
            "[01:44.900 --> 01:46.400] 一直權力很大\n",
            "[01:46.400 --> 01:49.500] 於是趁機就策劃了軍事政變\n",
            "[01:49.500 --> 01:51.100] 同年的12月12日\n",
            "[01:51.100 --> 01:52.400] 他帶領了一群軍官\n",
            "[01:52.400 --> 01:54.500] 佔領了首爾的關鍵軍事\n",
            "[01:54.500 --> 01:56.000] 跟政府的設施\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}