{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbrahamKong/Youtube_Summerizer/blob/main/Download_Youtube_Audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e0bd1f04",
      "metadata": {
        "id": "e0bd1f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e7f5c2-9aeb-4a2a-b189-6f97ef061abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2023.11.17)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.1\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.84.0)\n",
            "Collecting google-api-python-client\n",
            "  Downloading google_api_python_client-2.111.0-py2.py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<1.dev0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.62.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.1.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.11.17)\n",
            "Installing collected packages: google-api-python-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "Successfully installed google-api-python-client-2.111.0\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-f947ma08\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-f947ma08\n",
            "  Resolved https://github.com/openai/whisper.git to commit 8bc8860694949db53c42ba47ddc23786c2e02a8b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801404 sha256=275900385fca1b33f57b67744eea5d1d84dffe3d371763e6367382f073ec6c45\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6adqr_ul/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.2\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [634 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,326 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,305 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,046 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,599 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [39.8 kB]\n",
            "Fetched 6,317 kB in 2s (3,595 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "28 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n",
            "Collecting yt_dlp\n",
            "  Downloading yt_dlp-2023.11.16-py2.py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen (from yt_dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt_dlp)\n",
            "  Downloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets (from yt_dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2023.11.17)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2.0.7)\n",
            "Collecting brotli (from yt_dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt_dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt_dlp) (3.6)\n",
            "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, yt_dlp\n",
            "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.19.0 websockets-12.0 yt_dlp-2023.11.16\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=c83bb7ca9f05647dace70697b7da86cd3f41b83918dde8eb1992a80464c443a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ],
      "source": [
        "# !pip install youtube-transcript-api\n",
        "# !pip install --upgrade google-api-python-client\n",
        "# !pip install openai==0.28\n",
        "\n",
        "# # For Audio to text\n",
        "# # install openai's whisper\n",
        "# !pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "# # update the packages\n",
        "# !sudo apt update && sudo apt install ffmpeg\n",
        "\n",
        "# # For Downloading Youtube Audio\n",
        "# !pip install yt_dlp\n",
        "# !pip install ffmpeg\n",
        "# !mkdir youtubeaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "27237d25",
      "metadata": {
        "id": "27237d25"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Download Youtube WAV\n",
        "from __future__ import unicode_literals\n",
        "import yt_dlp\n",
        "import ffmpeg\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOUTUBE_API_KEY = ''\n",
        "OPENAI_API_KEY = 'sk-'"
      ],
      "metadata": {
        "id": "j2tSAowWkiZ8"
      },
      "id": "j2tSAowWkiZ8",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to extract youtube video ID from the URL"
      ],
      "metadata": {
        "id": "hYpPxTysk6Em"
      },
      "id": "hYpPxTysk6Em"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_video_id_from_url(url):\n",
        "    \"\"\"\n",
        "    Extracts the YouTube video ID from a given URL.\n",
        "    \"\"\"\n",
        "    regex = r\"(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})\"\n",
        "    match = re.search(regex, url)\n",
        "    return match.group(1) if match else None"
      ],
      "metadata": {
        "id": "si7lmMdWk7Hx"
      },
      "id": "si7lmMdWk7Hx",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to fetch the author, title and description of the youtube video"
      ],
      "metadata": {
        "id": "CP75fnXnk8-E"
      },
      "id": "CP75fnXnk8-E"
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "def get_youtube_video_details(url, youtube_api_key):\n",
        "    \"\"\"\n",
        "    Fetches details of a YouTube video given its URL.\n",
        "    \"\"\"\n",
        "    video_id = extract_video_id_from_url(url)\n",
        "\n",
        "    # Initialize YouTube API client\n",
        "    youtube = build('youtube', 'v3', developerKey=youtube_api_key)\n",
        "    request = youtube.videos().list(part=\"snippet\", id=video_id)\n",
        "    response = request.execute()\n",
        "\n",
        "    if 'items' in response and len(response['items']) > 0:\n",
        "        title = response['items'][0]['snippet']['title']\n",
        "        author = response['items'][0]['snippet']['channelTitle']\n",
        "        description = response['items'][0]['snippet']['description']\n",
        "        return title, author, description\n",
        "    else:\n",
        "        return \"Video not found\", \"\", \"\""
      ],
      "metadata": {
        "id": "BTEr2LoJk-J6"
      },
      "id": "BTEr2LoJk-J6",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound\n",
        "\n",
        "def get_video_transcript(video_url):\n",
        "    try:\n",
        "        video_id = extract_video_id_from_url(video_url)\n",
        "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "\n",
        "        # Fetch the transcript in English or the first available transcript\n",
        "        if transcript_list.find_transcript(['en']):\n",
        "            transcript = transcript_list.find_transcript(['en']).fetch()\n",
        "        else:\n",
        "            transcript = transcript_list[0].fetch()\n",
        "\n",
        "        # Combine the text of the transcript\n",
        "        combined_transcript = ' '.join([t['text'] for t in transcript])\n",
        "        return combined_transcript\n",
        "    except NoTranscriptFound:\n",
        "        return \"No transcript found for this video.\""
      ],
      "metadata": {
        "id": "hbaGNaflk_iZ"
      },
      "id": "hbaGNaflk_iZ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to summarize the youtube video using OpenAI API"
      ],
      "metadata": {
        "id": "fgXHHKd2lB7Q"
      },
      "id": "fgXHHKd2lB7Q"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def summarize_text(text, openai_api_key):\n",
        "    \"\"\"\n",
        "    Summarizes the given text using OpenAI's GPT-3.\n",
        "    \"\"\"\n",
        "    openai.api_key = openai_api_key\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Summarize the following text:\\n\\n{text}\"}\n",
        "        ],\n",
        "        max_tokens=1500\n",
        "    )\n",
        "\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "def split_text_into_chunks(text, chunk_size=4000):\n",
        "    \"\"\"\n",
        "    Splits text into smaller chunks, each with a maximum of chunk_size characters.\n",
        "    \"\"\"\n",
        "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "def summarize_large_text(text, openai_api_key):\n",
        "    \"\"\"\n",
        "    Splits a large text into chunks and summarizes each chunk.\n",
        "    \"\"\"\n",
        "    chunks = split_text_into_chunks(text)\n",
        "    summaries = [summarize_text(chunk, openai_api_key) for chunk in chunks]\n",
        "    return ' '.join(summaries)\n",
        "\n"
      ],
      "metadata": {
        "id": "YwHk7HB1lF9Q"
      },
      "id": "YwHk7HB1lF9Q",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to download youtube audio"
      ],
      "metadata": {
        "id": "XzYok5m0lHsE"
      },
      "id": "XzYok5m0lHsE"
    },
    {
      "cell_type": "code",
      "source": [
        "def download_youtube_audio(title, url):\n",
        "  # Download options\n",
        "  ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'wav',\n",
        "    }],\n",
        "    \"outtmpl\": f'youtubeaudio/{title}',  # Output template\n",
        "  }\n",
        "\n",
        "  # Function to download from URL\n",
        "  with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "      ydl.download([url])"
      ],
      "metadata": {
        "id": "s6yJFkBvXbat"
      },
      "id": "s6yJFkBvXbat",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the audio to speech-to-text"
      ],
      "metadata": {
        "id": "Y2EXqVwzlTRs"
      },
      "id": "Y2EXqVwzlTRs"
    },
    {
      "cell_type": "code",
      "source": [
        "def speech_to_text(AUDIO_PATH):\n",
        "  # Run Whisper AI:\n",
        "  !whisper {AUDIO_PATH} --model medium\n",
        "\n",
        "  # Additional arguments:\n",
        "  !whisper -h"
      ],
      "metadata": {
        "id": "7SfSl3SxlUsZ"
      },
      "id": "7SfSl3SxlUsZ",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_transcript(url):\n",
        "  # Grab Youtube title to name the audio file\n",
        "  title, author, description = get_youtube_video_details(url, YOUTUBE_API_KEY)\n",
        "  AUDIO_NAME = title.replace(\" \", \"_\")\n",
        "\n",
        "  download_youtube_audio(AUDIO_NAME, url)\n",
        "\n",
        "  audio_path = ('/content/youtubeaudio/' + AUDIO_NAME + \".wav\")\n",
        "  # print(\"AUDIOPATH IS \" + audio_path)\n",
        "\n",
        "  speech_to_text(audio_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "AwYpN878mj19"
      },
      "id": "AwYpN878mj19",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "\n",
        "Youtube_url = \"https://youtu.be/HKoOBiAaHGg'\"\n",
        "\n",
        "generate_transcript(Youtube_url)"
      ],
      "metadata": {
        "id": "CBf63ZvMnEPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed67613a-0d35-4210-9dc7-7cd4b2d63831"
      },
      "id": "CBf63ZvMnEPg",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/HKoOBiAaHGg'\n",
            "[youtube] HKoOBiAaHGg: Downloading webpage\n",
            "[youtube] HKoOBiAaHGg: Downloading ios player API JSON\n",
            "[youtube] HKoOBiAaHGg: Downloading android player API JSON\n",
            "[youtube] HKoOBiAaHGg: Downloading player d23221b6\n",
            "[youtube] HKoOBiAaHGg: Downloading m3u8 information\n",
            "[info] HKoOBiAaHGg: Downloading 1 format(s): 251\n",
            "[download] Destination: youtubeaudio/How_to_Deploy_Your_App_to_Streamlit_Community_Cloud\n",
            "[download] 100% of    9.29MiB in 00:00:00 at 17.78MiB/s  \n",
            "[ExtractAudio] Destination: youtubeaudio/How_to_Deploy_Your_App_to_Streamlit_Community_Cloud.wav\n",
            "Deleting original file youtubeaudio/How_to_Deploy_Your_App_to_Streamlit_Community_Cloud (pass -k to keep)\n",
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:39<00:00, 39.1MiB/s]\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:04.640]  So you have just created your Streamlit application, but you don't want to keep it to yourself\n",
            "[00:04.640 --> 00:07.640]  because you want to share your awesome creation with the world.\n",
            "[00:07.640 --> 00:11.880]  So in this video, I'm going to show you how you could deploy your Streamlit app to the\n",
            "[00:11.880 --> 00:15.240]  Streamlit Community Cloud, and best of all, it's for free.\n",
            "[00:15.240 --> 00:18.160]  So if this sounds like fun, then this video is for you.\n",
            "[00:18.160 --> 00:22.680]  And without further ado, we're starting right now.\n",
            "[00:22.680 --> 00:26.280]  Let's have a look at some of the contents that we're going to be covering today.\n",
            "[00:26.280 --> 00:31.160]  I'm going to show you a five-step process where you could go from step one, building\n",
            "[00:31.160 --> 00:36.760]  a Streamlit app, step two, setting up a Streamlit Community Cloud account, step three, connect\n",
            "[00:36.760 --> 00:42.160]  your GitHub account to the Community Cloud, step four, create a GitHub repo with your\n",
            "[00:42.160 --> 00:48.240]  app, and step five, deploy your Streamlit app to the Community Cloud in just a few clicks.\n",
            "[00:48.240 --> 00:53.880]  So before showing you how to actually deploy your app, let's take a short moment to consider\n",
            "[00:53.880 --> 00:59.280]  the high-level overview of why do you need to deploy your Streamlit app to the cloud.\n",
            "[00:59.280 --> 01:04.160]  So obviously, the most important reason is that you want to share your creation with\n",
            "[01:04.160 --> 01:10.000]  the entire world to see, to make use of, or perhaps to give you comments, feedbacks, and\n",
            "[01:10.000 --> 01:11.320]  points for improvement.\n",
            "[01:11.320 --> 01:15.820]  And best of all, anyone in the world could have access to your app without installing\n",
            "[01:15.820 --> 01:20.960]  any prerequisite Python libraries, as they are able to access the functionality of the\n",
            "[01:20.960 --> 01:23.120]  app right inside their browser.\n",
            "[01:23.120 --> 01:27.800]  So in a nutshell, you have generally two options for deploying your Streamlit app.\n",
            "[01:27.800 --> 01:32.160]  The first one is to manually set up your virtual private server and then configure everything\n",
            "[01:32.160 --> 01:35.360]  so that it works together and your app is hosted.\n",
            "[01:35.360 --> 01:40.320]  Option number two is to use a cloud platform where essentially you could upload your app\n",
            "[01:40.320 --> 01:45.880]  repo onto the GitHub and then connect it to the cloud platform so that it could be hosted.\n",
            "[01:45.880 --> 01:48.780]  And so in this video, we're going to cover the second approach.\n",
            "[01:48.780 --> 01:53.460]  And the reason being is that it's the simplest approach and it will allow you to get up and\n",
            "[01:53.460 --> 01:54.860]  running in no time.\n",
            "[01:54.860 --> 01:58.960]  And of course, the first option where you could create your own private server provides\n",
            "[01:58.960 --> 02:03.780]  you with full control, but then the time and cost involved in setting up the platform would\n",
            "[02:03.780 --> 02:07.140]  require a hefty investment of time and cost.\n",
            "[02:07.140 --> 02:12.460]  So here are some of the reasons why you want to deploy your Streamlit app to the Streamlit\n",
            "[02:12.460 --> 02:13.460]  Community Cloud.\n",
            "[02:13.460 --> 02:15.660]  So the first advantage is that it's free.\n",
            "[02:15.660 --> 02:18.700]  You could deploy your Streamlit apps at no charge.\n",
            "[02:18.700 --> 02:22.820]  Advantage number two, you could deploy it in a few clicks and your fully hosted app\n",
            "[02:22.820 --> 02:25.220]  will be shareable in a few minutes.\n",
            "[02:25.220 --> 02:29.620]  Third advantage is that all of your code is on the cloud in the GitHub repo and this allows\n",
            "[02:29.620 --> 02:31.980]  you to collaborate with your peers.\n",
            "[02:31.980 --> 02:36.060]  Fourth advantage is that it supports live updates to your code so that whenever you\n",
            "[02:36.060 --> 02:40.940]  push a new code change, your Streamlit app will be updated in real time.\n",
            "[02:40.940 --> 02:44.620]  Advantage number five is that you'll be able to securely connect to your data where you\n",
            "[02:44.620 --> 02:48.860]  could connect to all of your data sources using secure protocols.\n",
            "[02:48.860 --> 02:54.140]  Advantage number six, you could restrict access to apps, though by default you'll have access\n",
            "[02:54.140 --> 02:59.220]  to one private app that will allow you to create an app that is not yet ready for the\n",
            "[02:59.220 --> 03:02.340]  public and when it's ready, you could make it public.\n",
            "[03:02.340 --> 03:07.500]  Advantage number seven, you could easily manage all of your Streamlit apps in one control\n",
            "[03:07.500 --> 03:12.420]  center, which will allow you to collaborate with your peers, name or rename your Streamlit\n",
            "[03:12.420 --> 03:16.660]  apps and just generally have a glance in one view all of the apps that you have just\n",
            "[03:16.660 --> 03:17.660]  created.\n",
            "[03:17.660 --> 03:23.660]  All right, and so the first step is to create your Streamlit app and so I'm going to launch\n",
            "[03:23.660 --> 03:31.780]  the Atom IDE on my computer or you could use any other code editor as well.\n",
            "[03:31.780 --> 03:33.580]  So let's create a simple app.\n",
            "[03:33.580 --> 03:43.420]  We're going to import Streamlit as st, then we're going to say st.write and then I'm going\n",
            "[03:43.420 --> 03:53.660]  to say hello world and then we're going to save it.\n",
            "[03:53.660 --> 03:55.060]  We're going to save it to the desktop.\n",
            "[03:55.060 --> 03:59.260]  I'll call it Streamlit app.py.\n",
            "[03:59.500 --> 04:09.020]  So the next step is I'll set up an account on this Streamlit community cloud.\n",
            "[04:09.020 --> 04:20.140]  You could go to streamlit.io slash cloud and then you can see here that all of the high\n",
            "[04:20.140 --> 04:26.660]  level overview is provided here on this web page and you could go ahead and click on sign\n",
            "[04:26.740 --> 04:32.420]  up.\n",
            "[04:32.420 --> 04:39.020]  So you could sign up by continuing by using your Google credentials or your GitHub credentials\n",
            "[04:39.020 --> 04:44.100]  as well or you could also sign up using the traditional approach of putting in your email.\n",
            "[04:44.100 --> 04:51.580]  So let me use my GitHub account.\n",
            "[04:51.700 --> 05:01.500]  So here you put in your GitHub username and then your password and so when you're logging\n",
            "[05:01.500 --> 05:05.260]  in for the first time it's going to ask you for permission.\n",
            "[05:05.260 --> 05:09.740]  So you could authorize Streamlit to have access to your GitHub repo.\n",
            "[05:09.740 --> 05:15.940]  So click on authorize Streamlit and wait just a moment so that you'll be able to deploy\n",
            "[05:15.940 --> 05:21.860]  your app directly from GitHub and click again authorize Streamlit.\n",
            "[05:21.860 --> 05:27.380]  Alright and so you're logged in to the community cloud and because you haven't yet deployed\n",
            "[05:27.380 --> 05:30.980]  your app you're going to see an empty yellow box here.\n",
            "[05:30.980 --> 05:34.980]  So you could go ahead and deploy your first app by clicking new app if you already have\n",
            "[05:34.980 --> 05:40.300]  a GitHub repo but we haven't yet built one so I'm going to show you in just a moment.\n",
            "[05:40.300 --> 05:48.780]  So why don't you go ahead and click on settings and then go to here in the source control\n",
            "[05:48.780 --> 05:54.020]  I am logged in as coding professor using GitHub and so you can see here that you are allocated\n",
            "[05:54.020 --> 06:00.380]  one gigabyte per app and you are able to create one private app and you're also able to create\n",
            "[06:00.380 --> 06:06.140]  an unlimited number of public apps and these are some of the support information just in\n",
            "[06:06.140 --> 06:11.060]  case you have any questions or need help you could check out the documentations and also\n",
            "[06:11.060 --> 06:16.540]  the forums and this board so you can see that because we're logging in using our GitHub\n",
            "[06:16.540 --> 06:21.220]  account the Streamlit community cloud already have access to your GitHub repos and so you\n",
            "[06:21.220 --> 06:23.660]  don't need to do any configuration here.\n",
            "[06:23.660 --> 06:29.860]  However if you have signed up using your Google account then you have to also provide authorization\n",
            "[06:29.860 --> 06:35.100]  for your GitHub account as well and it's as simple as clicking on the link here and then\n",
            "[06:35.100 --> 06:39.300]  providing authorization similar to the one that I've just shown you in just a few moments\n",
            "[06:39.300 --> 06:40.300]  ago.\n",
            "[06:40.300 --> 06:44.980]  Alright so now that we have already connected our GitHub to the Streamlit community cloud\n",
            "[06:44.980 --> 06:50.220]  the next step here step number four is to create a GitHub repo for your Streamlit app\n",
            "[06:50.220 --> 06:58.180]  so let's go ahead and go to GitHub and I have already created a repo app here but I'm going\n",
            "[06:58.580 --> 07:08.540]  a new one to show you go ahead and click on new and let me see I'll say hello app and\n",
            "[07:08.540 --> 07:15.860]  I'll make it public and I'll tick on adding a readme file and then you could click on\n",
            "[07:15.860 --> 07:27.100]  the create repository alright and now you could just click on add file create new file\n",
            "[07:27.100 --> 07:37.860]  and then you want to type in Streamlit app.py and then for the contents here you could copy\n",
            "[07:37.860 --> 07:45.100]  and then paste it here or you could also upload the file to your GitHub repo as well and uploading\n",
            "[07:45.100 --> 07:52.300]  is as simple as clicking here in the add file and clicking upload files and then you could\n",
            "[07:52.300 --> 07:59.620]  just drag and drop the file or you could select it from here and then select the file\n",
            "[07:59.620 --> 08:06.460]  and then open because I have already created the file then I'll just skip this part because\n",
            "[08:06.460 --> 08:13.620]  we already have this Streamlit app.py file and let's do a double check click on the file\n",
            "[08:13.620 --> 08:18.140]  and then here we have a very simple app that will write out the hello world statement on\n",
            "[08:18.140 --> 08:26.060]  your app alright so let's deploy the app here and so this is step number five we're going to\n",
            "[08:26.060 --> 08:30.740]  deploy your Streamlit app to the Streamlit community cloud so go ahead and click on new\n",
            "[08:30.740 --> 08:39.620]  app and then in the repository drop-down menu here you want to click on it and then click on\n",
            "[08:40.380 --> 08:52.020]  the repo that we have just created and then the branch here is main because it is main here as\n",
            "[08:52.020 --> 09:05.740]  well and then the name of the file is Streamlit app.py and go ahead and click on deploy and so\n",
            "[09:05.740 --> 09:11.500]  allow a few moments for the app to be deployed on the server and you'll notice here that this\n",
            "[09:11.500 --> 09:17.340]  is the URL that the server has created for you and if you would like to have a shorter version\n",
            "[09:17.340 --> 09:24.540]  of the app name you could go and rename the app so I'll show you in just a moment let's wait for\n",
            "[09:24.540 --> 09:28.980]  the app to be deployed first in the meantime you could click on the manage app and you'll be able\n",
            "[09:29.060 --> 09:37.900]  to see the log so just in case if there's any error you will be able to see in here you can see\n",
            "[09:37.900 --> 09:43.820]  here that it has already done all of the installation of the prerequisite libraries in order to create\n",
            "[09:43.820 --> 09:49.820]  the server so this server is created just for you on the fly and so when you have clicked on the\n",
            "[09:49.820 --> 09:55.660]  deploy button this particular server has been instantiated and created just for you and so\n",
            "[09:55.660 --> 10:00.340]  there you go you see on the left hand side that your app is already deployed to the Streamlit\n",
            "[10:00.340 --> 10:05.900]  community cloud and you can see the statement hello world all right and so as promised I'm\n",
            "[10:05.900 --> 10:11.460]  going to show you how you could rename your Streamlit app so go ahead and go back to your\n",
            "[10:11.460 --> 10:19.580]  control center of the community cloud you could just type in share.streamlit.io all right and so\n",
            "[10:19.580 --> 10:25.300]  this is the app that you have just deployed hello app and if you click on it you're going\n",
            "[10:25.300 --> 10:32.700]  to go to the app that was just launched a few moments ago and so in this button here you want\n",
            "[10:32.700 --> 10:39.020]  to click on it go and click on settings and here you could rename it you could rename it to hello\n",
            "[10:39.020 --> 10:58.020]  app it has already been taken how about hello app here how about coding hello save it and now\n",
            "[10:58.020 --> 11:06.900]  your app will be available at coding-hello.streamlit.app see it's coding-hello.streamlit.app\n",
            "[11:09.020 --> 11:17.220]  so congratulations you've deployed your first Streamlit app to the cloud using the Streamlit\n",
            "[11:17.220 --> 11:22.700]  community cloud if you found the video helpful don't forget to like and subscribe and also\n",
            "[11:22.700 --> 11:27.100]  turn on notifications and I'll see you in the next video happy streamliting\n",
            "usage: whisper [-h] [--model MODEL] [--model_dir MODEL_DIR] [--device DEVICE]\n",
            "               [--output_dir OUTPUT_DIR] [--output_format {txt,vtt,srt,tsv,json,all}]\n",
            "               [--verbose VERBOSE] [--task {transcribe,translate}]\n",
            "               [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
            "               [--temperature TEMPERATURE] [--best_of BEST_OF] [--beam_size BEAM_SIZE]\n",
            "               [--patience PATIENCE] [--length_penalty LENGTH_PENALTY]\n",
            "               [--suppress_tokens SUPPRESS_TOKENS] [--initial_prompt INITIAL_PROMPT]\n",
            "               [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT] [--fp16 FP16]\n",
            "               [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
            "               [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
            "               [--logprob_threshold LOGPROB_THRESHOLD] [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
            "               [--word_timestamps WORD_TIMESTAMPS] [--prepend_punctuations PREPEND_PUNCTUATIONS]\n",
            "               [--append_punctuations APPEND_PUNCTUATIONS] [--highlight_words HIGHLIGHT_WORDS]\n",
            "               [--max_line_width MAX_LINE_WIDTH] [--max_line_count MAX_LINE_COUNT]\n",
            "               [--max_words_per_line MAX_WORDS_PER_LINE] [--threads THREADS]\n",
            "               audio [audio ...]\n",
            "\n",
            "positional arguments:\n",
            "  audio                 audio file(s) to transcribe\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model MODEL         name of the Whisper model to use (default: small)\n",
            "  --model_dir MODEL_DIR\n",
            "                        the path to save model files; uses ~/.cache/whisper by default (default:\n",
            "                        None)\n",
            "  --device DEVICE       device to use for PyTorch inference (default: cuda)\n",
            "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
            "                        directory to save the outputs (default: .)\n",
            "  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n",
            "                        format of the output file; if not specified, all available formats will be\n",
            "                        produced (default: all)\n",
            "  --verbose VERBOSE     whether to print out the progress and debug messages (default: True)\n",
            "  --task {transcribe,translate}\n",
            "                        whether to perform X->X speech recognition ('transcribe') or X->English\n",
            "                        translation ('translate') (default: transcribe)\n",
            "  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n",
            "                        language spoken in the audio, specify None to perform language detection\n",
            "                        (default: None)\n",
            "  --temperature TEMPERATURE\n",
            "                        temperature to use for sampling (default: 0)\n",
            "  --best_of BEST_OF     number of candidates when sampling with non-zero temperature (default: 5)\n",
            "  --beam_size BEAM_SIZE\n",
            "                        number of beams in beam search, only applicable when temperature is zero\n",
            "                        (default: 5)\n",
            "  --patience PATIENCE   optional patience value to use in beam decoding, as in\n",
            "                        https://arxiv.org/abs/2204.05424, the default (1.0) is equivalent to\n",
            "                        conventional beam search (default: None)\n",
            "  --length_penalty LENGTH_PENALTY\n",
            "                        optional token length penalty coefficient (alpha) as in\n",
            "                        https://arxiv.org/abs/1609.08144, uses simple length normalization by\n",
            "                        default (default: None)\n",
            "  --suppress_tokens SUPPRESS_TOKENS\n",
            "                        comma-separated list of token ids to suppress during sampling; '-1' will\n",
            "                        suppress most special characters except common punctuations (default: -1)\n",
            "  --initial_prompt INITIAL_PROMPT\n",
            "                        optional text to provide as a prompt for the first window. (default: None)\n",
            "  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n",
            "                        if True, provide the previous output of the model as a prompt for the next\n",
            "                        window; disabling may make the text inconsistent across windows, but the\n",
            "                        model becomes less prone to getting stuck in a failure loop (default:\n",
            "                        True)\n",
            "  --fp16 FP16           whether to perform inference in fp16; True by default (default: True)\n",
            "  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n",
            "                        temperature to increase when falling back when the decoding fails to meet\n",
            "                        either of the thresholds below (default: 0.2)\n",
            "  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n",
            "                        if the gzip compression ratio is higher than this value, treat the\n",
            "                        decoding as failed (default: 2.4)\n",
            "  --logprob_threshold LOGPROB_THRESHOLD\n",
            "                        if the average log probability is lower than this value, treat the\n",
            "                        decoding as failed (default: -1.0)\n",
            "  --no_speech_threshold NO_SPEECH_THRESHOLD\n",
            "                        if the probability of the <|nospeech|> token is higher than this value AND\n",
            "                        the decoding has failed due to `logprob_threshold`, consider the segment\n",
            "                        as silence (default: 0.6)\n",
            "  --word_timestamps WORD_TIMESTAMPS\n",
            "                        (experimental) extract word-level timestamps and refine the results based\n",
            "                        on them (default: False)\n",
            "  --prepend_punctuations PREPEND_PUNCTUATIONS\n",
            "                        if word_timestamps is True, merge these punctuation symbols with the next\n",
            "                        word (default: \"'“¿([{-)\n",
            "  --append_punctuations APPEND_PUNCTUATIONS\n",
            "                        if word_timestamps is True, merge these punctuation symbols with the\n",
            "                        previous word (default: \"'.。,，!！?？:：”)]}、)\n",
            "  --highlight_words HIGHLIGHT_WORDS\n",
            "                        (requires --word_timestamps True) underline each word as it is spoken in\n",
            "                        srt and vtt (default: False)\n",
            "  --max_line_width MAX_LINE_WIDTH\n",
            "                        (requires --word_timestamps True) the maximum number of characters in a\n",
            "                        line before breaking the line (default: None)\n",
            "  --max_line_count MAX_LINE_COUNT\n",
            "                        (requires --word_timestamps True) the maximum number of lines in a segment\n",
            "                        (default: None)\n",
            "  --max_words_per_line MAX_WORDS_PER_LINE\n",
            "                        (requires --word_timestamps True, no effect with --max_line_width) the\n",
            "                        maximum number of words in a segment (default: None)\n",
            "  --threads THREADS     number of threads used by torch for CPU inference; supercedes\n",
            "                        MKL_NUM_THREADS/OMP_NUM_THREADS (default: 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "\n",
        "Youtube_url = \"https://youtu.be/qijcT0LnqdU\"\n",
        "\n",
        "generate_transcript(Youtube_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfStfl2XmSgU",
        "outputId": "0dd34720-56d1-40d3-d13d-d27b310c2217"
      },
      "id": "QfStfl2XmSgU",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/qijcT0LnqdU\n",
            "[youtube] qijcT0LnqdU: Downloading webpage\n",
            "[youtube] qijcT0LnqdU: Downloading ios player API JSON\n",
            "[youtube] qijcT0LnqdU: Downloading android player API JSON\n",
            "[youtube] qijcT0LnqdU: Downloading m3u8 information\n",
            "[info] qijcT0LnqdU: Downloading 1 format(s): 251\n",
            "[download] Destination: youtubeaudio/看《首爾之春》氣到要測心跳？韓年輕世代起「心率挑戰」運動！這個影響韓國近代史的重大事件是什麼？_【TODAY_看世界】\n",
            "[download] 100% of    8.14MiB in 00:00:00 at 22.51MiB/s  \n",
            "[ExtractAudio] Destination: youtubeaudio/看《首爾之春》氣到要測心跳？韓年輕世代起「心率挑戰」運動！這個影響韓國近代史的重大事件是什麼？_【TODAY_看世界】.wav\n",
            "Deleting original file youtubeaudio/看《首爾之春》氣到要測心跳？韓年輕世代起「心率挑戰」運動！這個影響韓國近代史的重大事件是什麼？_【TODAY_看世界】 (pass -k to keep)\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Chinese\n",
            "[00:00.000 --> 00:02.200] 你最近一次去電影院看電影\n",
            "[00:02.200 --> 00:03.300] 是什麼時候\n",
            "[00:03.300 --> 00:04.600] 這幾年因為疫情\n",
            "[00:04.600 --> 00:06.800] 加上影音串流平台的興起\n",
            "[00:06.800 --> 00:09.300] 願意去電影院的人越來越少了\n",
            "[00:09.300 --> 00:10.300] 韓國也差不多\n",
            "[00:10.300 --> 00:11.700] 但最近有一部叫做\n",
            "[00:11.700 --> 00:13.900] 《一二一二首爾之春》的電影\n",
            "[00:13.900 --> 00:16.100] 卻在韓國掀起了風潮\n",
            "[00:16.100 --> 00:18.500] 上映12天就損一兩評\n",
            "[00:18.500 --> 00:21.300] 突破了465萬觀看人次\n",
            "[00:21.300 --> 00:23.700] 在韓國是叫好又叫做啊\n",
            "[00:23.700 --> 00:25.700] 這部電影講述了被稱為\n",
            "[00:25.700 --> 00:28.500] 光州屠夫的前總統權斗煥\n",
            "[00:28.600 --> 00:30.900] 在1979 12月12日\n",
            "[00:30.900 --> 00:33.100] 發起軍事政變的故事\n",
            "[00:33.100 --> 00:35.000] 權斗煥之前的故事我們提過\n",
            "[00:35.000 --> 00:36.600] 有興趣的可以去看看\n",
            "[00:36.600 --> 00:38.400] 這段歷史對韓國人來講\n",
            "[00:38.400 --> 00:41.100] 重要性好比台灣的二二八事件\n",
            "[00:41.100 --> 00:42.800] 大人是親身經歷\n",
            "[00:42.800 --> 00:44.900] 年輕人則是課本上讀過\n",
            "[00:44.900 --> 00:47.000] 但明知道歷史是這麼發生的\n",
            "[00:47.000 --> 00:49.200] 看電影的時候大家還是很生氣\n",
            "[00:49.200 --> 00:50.500] 韓國的年輕族群\n",
            "[00:50.500 --> 00:53.100] 還發起了心律挑戰運動\n",
            "[00:53.100 --> 00:55.300] 用智慧手錶量心跳數\n",
            "[00:55.300 --> 00:56.900] 看自己有多生氣\n",
            "[00:56.900 --> 00:58.400] 看電影還要量心跳\n",
            "[00:58.400 --> 01:00.000] 看自己的情緒有多激動\n",
            "[01:00.000 --> 01:01.500] 會不會太誇張了\n",
            "[01:01.500 --> 01:03.300] 這個影響韓國近代史的\n",
            "[01:03.300 --> 01:05.000] 重大事件是什麼\n",
            "[01:05.000 --> 01:07.300] 為什麼會讓以此題材的電影\n",
            "[01:07.300 --> 01:08.200] 這麼賣座呢\n",
            "[01:14.200 --> 01:15.100] 大家好 我是Fancy Fe\n",
            "[01:15.100 --> 01:15.900] 歡迎收看 Fancy Fe的\n",
            "[01:15.900 --> 01:17.500]  Today 看世界\n",
            "[01:17.500 --> 01:19.600] 這部電影會在台灣上演\n",
            "[01:19.600 --> 01:21.300] 但講的是歷史事件\n",
            "[01:21.300 --> 01:23.100] 應該沒有劇透的問題吧\n",
            "[01:23.100 --> 01:25.100] 1979年10月26日\n",
            "[01:25.100 --> 01:28.000] 韓國時任獨裁總統普政熙\n",
            "[01:28.000 --> 01:30.400] 被親信金載龜槍殺之後\n",
            "[01:30.400 --> 01:33.400] 人們都以為獨裁統治中要結束\n",
            "[01:33.400 --> 01:35.200] 民主之春要來了\n",
            "[01:35.200 --> 01:36.600] 但是普政熙的死\n",
            "[01:36.600 --> 01:38.200] 留下了權力真空\n",
            "[01:38.200 --> 01:40.600] 當時擔任國軍保安司令官的\n",
            "[01:40.600 --> 01:41.600] 權斗患\n",
            "[01:41.600 --> 01:43.300] 身兼調查刺殺案的\n",
            "[01:43.300 --> 01:44.900] 聯合搜查本部長\n",
            "[01:44.900 --> 01:46.400] 一直權力很大\n",
            "[01:46.400 --> 01:49.500] 於是趁機就策劃了軍事政變\n",
            "[01:49.500 --> 01:51.100] 同年的12月12日\n",
            "[01:51.100 --> 01:52.400] 他帶領了一群軍官\n",
            "[01:52.400 --> 01:54.500] 佔領了首爾的關鍵軍事\n",
            "[01:54.500 --> 01:56.000] 跟政府的設施\n",
            "[01:56.000 --> 01:57.300] 順利的掌握了\n",
            "[01:57.300 --> 01:59.800] 韓國實際軍事跟政治的權力\n",
            "[01:59.800 --> 02:01.300] 並且迅速的鞏固了\n",
            "[02:01.300 --> 02:02.700] 他的領導地位\n",
            "[02:02.700 --> 02:05.700] 首爾的民主春天就這樣結束了\n",
            "[02:05.700 --> 02:07.000] 政變成功之後\n",
            "[02:07.000 --> 02:10.000] 韓國又回到了獨裁威權統治\n",
            "[02:10.000 --> 02:12.100] 但民間要求恢復民主制度\n",
            "[02:12.100 --> 02:14.300] 減嚴的聲浪越演越烈\n",
            "[02:14.300 --> 02:15.200] 隔年5月\n",
            "[02:15.200 --> 02:17.100] 韓國西南部的光州市民\n",
            "[02:17.100 --> 02:19.400] 發起了大規模民主示威\n",
            "[02:19.400 --> 02:21.600] 卻被軍隊強力鎮壓\n",
            "[02:21.600 --> 02:24.300] 至少有241名平民死亡\n",
            "[02:24.300 --> 02:25.700] 數千人受傷\n",
            "[02:25.700 --> 02:27.300] 多人被捕入獄\n",
            "[02:27.300 --> 02:29.200] 這就是光州事件\n",
            "[02:29.200 --> 02:32.300] 這個故事對於老一輩觀眾來說很熟悉\n",
            "[02:32.300 --> 02:35.100] 但電影則是引起年輕觀眾的共鳴\n",
            "[02:35.100 --> 02:37.900] 有個大學生李英培就對KBS表示\n",
            "[02:37.900 --> 02:39.000] 我也是大學生\n",
            "[02:39.000 --> 02:41.200] 當時大學生站出來抗議的事件\n",
            "[02:41.200 --> 02:42.600] 引起了我的共鳴\n",
            "[02:42.600 --> 02:45.200] 我想了解更多的事件細節\n",
            "[02:45.200 --> 02:47.500] 很多觀眾也表示看完電影之後\n",
            "[02:47.500 --> 02:49.300] 想要自己找更多的內容\n",
            "[02:49.300 --> 02:50.600] 了解這段歷史\n",
            "[02:50.600 --> 02:52.300] 引起世代共鳴之後\n",
            "[02:52.300 --> 02:55.500] 原本要安葬權斗患的波州市市民\n",
            "[02:56.200 --> 02:59.100] 都跳出來反對權斗患葬在這裡\n",
            "[02:59.100 --> 03:00.700] 權斗患生前的遺願\n",
            "[03:00.700 --> 03:03.500] 是將其骨灰葬在韓國邊境\n",
            "[03:03.500 --> 03:05.500] 可以跳往北韓的地方\n",
            "[03:05.500 --> 03:07.200] 想要圓他的統一夢\n",
            "[03:07.200 --> 03:10.300] 但當地11個民間團體召開了記者會\n",
            "[03:10.300 --> 03:12.700] 明確表示反對將權斗患\n",
            "[03:12.700 --> 03:14.600] 葬在波州任何地方\n",
            "[03:14.600 --> 03:17.000] 甚至還說波州沒有任何一塊地方\n",
            "[03:17.000 --> 03:19.900] 可以讓屠夫權斗患安息長眠\n",
            "[03:19.900 --> 03:21.500] 原本考慮賣地的地主\n",
            "[03:21.500 --> 03:23.100] 最終也放棄交易\n",
            "[03:23.200 --> 03:26.200] 所以權斗患已經去世兩年多了\n",
            "[03:26.200 --> 03:28.100] 現在骨灰還是存放在\n",
            "[03:28.100 --> 03:30.000] 首爾嚴洗洞的家中\n",
            "[03:30.000 --> 03:31.300] 事情延變至此\n",
            "[03:31.300 --> 03:33.900] 他離遺願可能再也無法實現了\n",
            "[03:39.000 --> 03:40.700] 但也不是所有韓國人\n",
            "[03:40.700 --> 03:43.200] 對這部電影都持有同樣的想法\n",
            "[03:43.200 --> 03:45.200] 首爾送播去的一所小學\n",
            "[03:45.200 --> 03:48.100] 原本計劃帶六年級的學生去看電影\n",
            "[03:48.100 --> 03:51.100] 加強對歷史的深入理解跟敏感度\n",
            "[03:51.100 --> 03:53.000] 能夠強化社會科教育\n",
            "[03:53.000 --> 03:55.500] 及提升學生的公民意識\n",
            "[03:55.500 --> 03:56.800] 很有意義啊\n",
            "[03:56.800 --> 03:58.400] 沒想到保守的YouTube頻道\n",
            "[03:58.400 --> 04:00.800] 跟極右派的網友馬上抗議\n",
            "[04:00.800 --> 04:02.500] 除了在社群網站上\n",
            "[04:02.500 --> 04:04.200] 發表抗議的貼文\n",
            "[04:04.200 --> 04:06.900] 保守派YouTube頻道綜合研究所\n",
            "[04:06.900 --> 04:08.200] 還在影片中表示\n",
            "[04:08.200 --> 04:09.900] 這根本是左派教育\n",
            "[04:09.900 --> 04:12.100] 這麼骯髒的事情必須要停止\n",
            "[04:12.100 --> 04:13.400] 甚至還煽動網友\n",
            "[04:13.400 --> 04:15.200] 一起向教育部舉報\n",
            "[04:15.200 --> 04:15.900] 搞到最後\n",
            "[04:15.900 --> 04:18.100] 因為這些保守派人士的反對\n",
            "[04:18.100 --> 04:20.200] 學校只能夠委婉地表示\n",
            "[04:20.200 --> 04:22.600] 因為擔心可能帶來的負面影響\n",
            "[04:22.600 --> 04:25.100] 學生徒步移動到電影院的交通安全\n",
            "[04:25.100 --> 04:27.800] 以及未參加學生的公平問題\n",
            "[04:27.800 --> 04:30.300] 不得已要取消這個活動\n",
            "[04:30.300 --> 04:31.800] 話都你在講啊隨便啦\n",
            "[04:31.800 --> 04:33.600] 反正學校也是倒楣\n",
            "[04:33.600 --> 04:35.700] 韓國近年來有關社會批判\n",
            "[04:35.700 --> 04:38.400] 以及轉型正義為主題的電影很多\n",
            "[04:38.400 --> 04:41.000] 像是2011年上億的熔爐\n",
            "[04:41.000 --> 04:42.100] 原著故事\n",
            "[04:42.100 --> 04:44.800] 取自於光州的真實故事\n",
            "[04:44.800 --> 04:45.900] 電影的成功\n",
            "[04:45.900 --> 04:48.700] 不僅讓相關案件重新展開調查\n",
            "[04:48.700 --> 04:50.800] 還推動了立法機關修法\n",
            "[04:50.800 --> 04:53.900] 加強針對兒童以及身經障礙人士\n",
            "[04:53.900 --> 04:56.200] 有關性暴力犯罪的懲罰\n",
            "[04:56.200 --> 04:58.200] 這是透過電影對社會產生正面\n",
            "[04:58.200 --> 04:59.900] 影響一個很好的例子\n",
            "[04:59.900 --> 05:00.700] 我承認\n",
            "[05:00.700 --> 05:03.000] 我在看韓國有這麼多討論政治議題\n",
            "[05:03.000 --> 05:05.600] 而且票房還大大成功的影視作品\n",
            "[05:05.600 --> 05:07.000] 是很羨慕\n",
            "[05:07.000 --> 05:08.400] 轉頭回來看看台灣\n",
            "[05:08.400 --> 05:10.500] 我常常聽到我電影界的朋友在抱怨\n",
            "[05:10.500 --> 05:12.300] 台灣的電影就只有愛情片\n",
            "[05:12.300 --> 05:13.600] 或是賀歲片啦\n",
            "[05:13.600 --> 05:15.400] 如果要拍轉型正義等\n",
            "[05:15.400 --> 05:16.900] 觸碰到政治題材的電影\n",
            "[05:16.900 --> 05:18.200] 一定找不到錢\n",
            "[05:18.200 --> 05:19.700] 其實不是只有電影這樣\n",
            "[05:19.700 --> 05:22.200] 連我們做網路影片的都有這個說法\n",
            "[05:22.200 --> 05:24.400] 做政治的題目吃力不討好\n",
            "[05:24.400 --> 05:25.600] 很容易被炎上\n",
            "[05:25.600 --> 05:27.600] 一炎上業主就跑了\n",
            "[05:27.600 --> 05:28.900] 錢有多難找\n",
            "[05:28.900 --> 05:30.900] 拿流麻溝15號來講\n",
            "[05:30.900 --> 05:33.000] 這講的是白色恐怖時期\n",
            "[05:33.000 --> 05:35.600] 女性政治犯被關在綠島的故事\n",
            "[05:35.600 --> 05:37.700] 出名人姚文智跟端傳媒說\n",
            "[05:37.700 --> 05:39.200] 他先花三年時間\n",
            "[05:39.200 --> 05:41.200] 跟政府申請電影輔導金\n",
            "[05:41.200 --> 05:43.100] 然後再群眾集資\n",
            "[05:43.100 --> 05:45.900] 文策院國發基金看眾籌人氣不錯\n",
            "[05:45.900 --> 05:47.100] 決定投資一些\n",
            "[05:47.100 --> 05:48.500] 但還是不夠\n",
            "[05:48.500 --> 05:51.300] 他於是用美股300萬來招募股東\n",
            "[05:51.300 --> 05:52.600] 再加上親友團\n",
            "[05:52.600 --> 05:55.000] 然後還要再去跟銀行借錢\n",
            "[05:55.000 --> 05:56.800] 我之前訪問姚文智的時候\n",
            "[05:56.800 --> 05:58.300] 他也說為了要籌錢\n",
            "[05:58.300 --> 05:59.200] 他變得很胖\n",
            "[05:59.200 --> 06:00.500] 因為他的很多人脈\n",
            "[06:00.500 --> 06:03.100] 都是想請他吃頓好的就打發他\n",
            "[06:03.100 --> 06:04.100] 他找100個人\n",
            "[06:04.100 --> 06:05.600] 只有一個會掏錢\n",
            "[06:05.600 --> 06:06.600] 他東拼西奏\n",
            "[06:06.600 --> 06:09.500] 這才終於湊足了新的台幣8000萬\n",
            "[06:09.500 --> 06:10.600] 拍攝完成\n",
            "[06:10.600 --> 06:12.900] 最後上癮的時候票房還不錯\n",
            "[06:12.900 --> 06:14.500] 四周有4000多萬\n",
            "[06:14.500 --> 06:15.400] 討論也多\n",
            "[06:15.400 --> 06:16.400] 但有回本嗎\n",
            "[06:16.600 --> 06:17.400] 好像沒有\n",
            "[06:22.500 --> 06:23.000] 沒錯\n",
            "[06:23.000 --> 06:25.800] 台灣的電影產業規模是比不上韓國\n",
            "[06:25.800 --> 06:27.600] 但只是因為這樣嗎\n",
            "[06:27.600 --> 06:29.700] 台大歷史系周婉瑤教授\n",
            "[06:29.700 --> 06:31.200] 提出了一種看法\n",
            "[06:31.200 --> 06:33.000] 他認為最主要的原因\n",
            "[06:33.000 --> 06:35.300] 是我們轉型正義做得不夠\n",
            "[06:35.300 --> 06:37.700] 韓國轉型正義走在台灣之前\n",
            "[06:37.700 --> 06:40.200] 已經不知道有多少委員會成立\n",
            "[06:40.200 --> 06:41.800] 來調查真相\n",
            "[06:41.800 --> 06:42.600] 最重要的是\n",
            "[06:42.600 --> 06:45.500] 韓國的轉型正義包括形式正義\n",
            "[06:45.500 --> 06:49.000] 也就是對加害者進行司法審判\n",
            "[06:49.000 --> 06:49.900] 像拳頭萬\n",
            "[06:49.900 --> 06:51.700] 雖然後來被特赦\n",
            "[06:51.700 --> 06:54.900] 但當時被法院一多項罪名\n",
            "[06:54.900 --> 06:56.500] 一審判處死刑\n",
            "[06:56.500 --> 06:58.600] 二審判處無期徒刑\n",
            "[06:58.600 --> 06:59.500] 反觀台灣\n",
            "[06:59.500 --> 07:01.100] 很多白色恐怖的案件\n",
            "[07:01.100 --> 07:02.300] 雖然有賠償\n",
            "[07:02.300 --> 07:05.300] 但沒有人真的被問責或被判刑\n",
            "[07:05.300 --> 07:06.700] 在韓國的這些電影中\n",
            "[07:06.700 --> 07:07.800] 我們甚至可以知道\n",
            "[07:07.800 --> 07:09.500] 這些加害者真實的姓名\n",
            "[07:09.500 --> 07:11.900] 以及事後所受到的判決\n",
            "[07:11.900 --> 07:13.800] 但台灣要嘛官官相護\n",
            "[07:13.800 --> 07:15.700] 要嘛就是檔案未解密\n",
            "[07:15.700 --> 07:17.700] 我們連加害人士誰都不知道\n",
            "[07:17.700 --> 07:19.600] 是怎麼樣行事正義呢\n",
            "[07:19.600 --> 07:22.000] 此外民間對轉型正義這個概念\n",
            "[07:22.000 --> 07:23.900] 一直有很多質疑\n",
            "[07:23.900 --> 07:25.100] 很多人罵轉型正義\n",
            "[07:25.100 --> 07:27.200] 是在煽動民族情緒\n",
            "[07:27.200 --> 07:28.900] 挑撥族群和諧\n",
            "[07:28.900 --> 07:30.100] 只會卡在過去\n",
            "[07:30.100 --> 07:31.400] 不會看往未來\n",
            "[07:31.400 --> 07:32.100] 自作賠\n",
            "[07:32.100 --> 07:33.400] 我先幫你罵\n",
            "[07:33.400 --> 07:34.900] 如果要罵要有新的觀點\n",
            "[07:34.900 --> 07:36.500] 罵人也是要有創意的\n",
            "[07:36.500 --> 07:37.900] 也就是因為台灣社會\n",
            "[07:37.900 --> 07:40.100] 對轉型正義是不是正義\n",
            "[07:40.100 --> 07:41.300] 還在爭論\n",
            "[07:41.300 --> 07:43.700] 台灣的電影現在就已經夠難做了\n",
            "[07:43.800 --> 07:45.400] 你還要他去拍這種票房\n",
            "[07:45.400 --> 07:47.000] 風險這麼高的電影\n",
            "[07:47.000 --> 07:48.100] 這種類型的電影\n",
            "[07:48.100 --> 07:49.800] 還有另外一個很大的麻煩\n",
            "[07:49.800 --> 07:52.800] 就是很容易被批評不符史實\n",
            "[07:52.800 --> 07:54.400] 即使在片頭一開始就說了\n",
            "[07:54.400 --> 07:56.900] This is inspired by a true story\n",
            "[07:56.900 --> 07:59.100] 我是受真實事件啟發\n",
            "[07:59.100 --> 08:00.000] 才做的電影\n",
            "[08:00.000 --> 08:01.100] 我跟你講沒用\n",
            "[08:01.100 --> 08:03.000] 還是會一大堆人跳出來嘛\n",
            "[08:03.000 --> 08:04.400] 你斷章起義啦\n",
            "[08:04.400 --> 08:05.600] 你美化被害人\n",
            "[08:05.600 --> 08:06.800] 你美化強害人\n",
            "[08:06.800 --> 08:08.000] 穿那個衣服不對\n",
            "[08:08.000 --> 08:10.400] 但如果歷史類電影的最高目的\n",
            "[08:10.400 --> 08:12.700] 是要非常符合史實呢\n",
            "[08:12.700 --> 08:14.800] 你乾脆去看紀錄片算了\n",
            "[08:14.800 --> 08:15.600] 我是覺得啦\n",
            "[08:15.600 --> 08:18.000] 你要將歷史事件改編成電影\n",
            "[08:18.000 --> 08:19.300] 本來就應該要調整\n",
            "[08:19.300 --> 08:20.600] 讓故事有起伏\n",
            "[08:20.600 --> 08:22.000] 劇情也要有爆點\n",
            "[08:22.000 --> 08:24.200] 紀錄片也是要剪接的不是嗎\n",
            "[08:24.200 --> 08:25.100] 怎麼樣說故事\n",
            "[08:25.100 --> 08:26.300] 說到觀眾可以接受\n",
            "[08:26.300 --> 08:27.400] 要順口一點\n",
            "[08:27.400 --> 08:29.100] 大家才容易吞嘛\n",
            "[08:29.100 --> 08:30.700] 但是太扯也不行\n",
            "[08:30.700 --> 08:31.800] 明明是古代\n",
            "[08:31.800 --> 08:32.900] 結果穿個運動鞋\n",
            "[08:32.900 --> 08:34.000] 這個太隨便了\n",
            "[08:34.000 --> 08:36.100] 韓國電影就是很會說故事\n",
            "[08:36.100 --> 08:38.900] 在史實跟改編中取得平衡\n",
            "[08:38.900 --> 08:41.500] 從中間取得了商業化的成功\n",
            "[08:41.500 --> 08:43.300] 這是我們應該要學習的\n",
            "[08:43.300 --> 08:44.100] 而不是每一次\n",
            "[08:44.100 --> 08:45.200] 好不容易有一個相關的主題\n",
            "[08:45.200 --> 08:45.900] 做不出來\n",
            "[08:45.900 --> 08:48.200] 就說字不字編不符合史實啦\n",
            "[08:48.200 --> 08:48.900] 或是攻擊說\n",
            "[08:48.900 --> 08:50.500] 為什麼要掀開傷痛啦\n",
            "[08:50.500 --> 08:52.500] 甚至說這是政治抹黑\n",
            "[08:52.500 --> 08:54.100] 在我看大可不必如此\n",
            "[08:54.100 --> 08:55.400] 不願好好正視\n",
            "[08:55.400 --> 08:56.700] 曾經發生過的歷史\n",
            "[08:56.700 --> 08:58.900] 那才是真正可惜的地方\n",
            "[08:58.900 --> 09:00.100] 今天我想要問的是\n",
            "[09:00.100 --> 09:02.800] 你有推薦一轉新正義為題材的電影嗎\n",
            "[09:02.800 --> 09:04.000] 台灣以外的也可以哦\n",
            "[09:04.000 --> 09:05.100] 留言告訴我哦\n",
            "[09:05.100 --> 09:06.700] 我最近才看了大導演\n",
            "[09:06.700 --> 09:09.400] 馬丁史克西斯的新片《花月殺手》\n",
            "[09:09.400 --> 09:10.700] 講的是美國白人\n",
            "[09:10.700 --> 09:12.600] 殺原住民的那段歷史\n",
            "[09:12.600 --> 09:13.600] 很厲害\n",
            "[09:13.600 --> 09:14.400] 我預言明年\n",
            "[09:14.400 --> 09:15.300] 奧斯卡這部電影\n",
            "[09:15.300 --> 09:17.100] 一定會拿到很多的獎\n",
            "[09:17.100 --> 09:18.000] 你如果喜歡這個節目\n",
            "[09:18.000 --> 09:19.200] 趕快分享給更多人看\n",
            "[09:19.200 --> 09:20.800] 記得訂閱Line2Day官方帳號\n",
            "[09:20.800 --> 09:21.900] 它就每天把重要的新聞\n",
            "[09:21.900 --> 09:22.800] 包括這個節目\n",
            "[09:22.800 --> 09:23.900] 推送到你的手機裡\n",
            "[09:23.900 --> 09:24.500] 萬一錯過了\n",
            "[09:24.500 --> 09:25.600] 當然Line2Day國際藍波\n",
            "[09:25.600 --> 09:26.900] 也就有我們所有的報導\n",
            "[09:26.900 --> 09:28.000] 泛血的特略看世界\n",
            "[09:28.000 --> 09:29.300] 天文裡精選一則國際話題\n",
            "[09:29.300 --> 09:31.200] 帶你快速瞄懂世界大事\n",
            "[09:31.200 --> 09:32.200] 我們明天見\n",
            "[09:40.700 --> 09:41.400] by bwd6\n",
            "usage: whisper [-h] [--model MODEL] [--model_dir MODEL_DIR] [--device DEVICE]\n",
            "               [--output_dir OUTPUT_DIR] [--output_format {txt,vtt,srt,tsv,json,all}]\n",
            "               [--verbose VERBOSE] [--task {transcribe,translate}]\n",
            "               [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
            "               [--temperature TEMPERATURE] [--best_of BEST_OF] [--beam_size BEAM_SIZE]\n",
            "               [--patience PATIENCE] [--length_penalty LENGTH_PENALTY]\n",
            "               [--suppress_tokens SUPPRESS_TOKENS] [--initial_prompt INITIAL_PROMPT]\n",
            "               [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT] [--fp16 FP16]\n",
            "               [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
            "               [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
            "               [--logprob_threshold LOGPROB_THRESHOLD] [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
            "               [--word_timestamps WORD_TIMESTAMPS] [--prepend_punctuations PREPEND_PUNCTUATIONS]\n",
            "               [--append_punctuations APPEND_PUNCTUATIONS] [--highlight_words HIGHLIGHT_WORDS]\n",
            "               [--max_line_width MAX_LINE_WIDTH] [--max_line_count MAX_LINE_COUNT]\n",
            "               [--max_words_per_line MAX_WORDS_PER_LINE] [--threads THREADS]\n",
            "               audio [audio ...]\n",
            "\n",
            "positional arguments:\n",
            "  audio                 audio file(s) to transcribe\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model MODEL         name of the Whisper model to use (default: small)\n",
            "  --model_dir MODEL_DIR\n",
            "                        the path to save model files; uses ~/.cache/whisper by default (default:\n",
            "                        None)\n",
            "  --device DEVICE       device to use for PyTorch inference (default: cuda)\n",
            "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
            "                        directory to save the outputs (default: .)\n",
            "  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n",
            "                        format of the output file; if not specified, all available formats will be\n",
            "                        produced (default: all)\n",
            "  --verbose VERBOSE     whether to print out the progress and debug messages (default: True)\n",
            "  --task {transcribe,translate}\n",
            "                        whether to perform X->X speech recognition ('transcribe') or X->English\n",
            "                        translation ('translate') (default: transcribe)\n",
            "  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n",
            "                        language spoken in the audio, specify None to perform language detection\n",
            "                        (default: None)\n",
            "  --temperature TEMPERATURE\n",
            "                        temperature to use for sampling (default: 0)\n",
            "  --best_of BEST_OF     number of candidates when sampling with non-zero temperature (default: 5)\n",
            "  --beam_size BEAM_SIZE\n",
            "                        number of beams in beam search, only applicable when temperature is zero\n",
            "                        (default: 5)\n",
            "  --patience PATIENCE   optional patience value to use in beam decoding, as in\n",
            "                        https://arxiv.org/abs/2204.05424, the default (1.0) is equivalent to\n",
            "                        conventional beam search (default: None)\n",
            "  --length_penalty LENGTH_PENALTY\n",
            "                        optional token length penalty coefficient (alpha) as in\n",
            "                        https://arxiv.org/abs/1609.08144, uses simple length normalization by\n",
            "                        default (default: None)\n",
            "  --suppress_tokens SUPPRESS_TOKENS\n",
            "                        comma-separated list of token ids to suppress during sampling; '-1' will\n",
            "                        suppress most special characters except common punctuations (default: -1)\n",
            "  --initial_prompt INITIAL_PROMPT\n",
            "                        optional text to provide as a prompt for the first window. (default: None)\n",
            "  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n",
            "                        if True, provide the previous output of the model as a prompt for the next\n",
            "                        window; disabling may make the text inconsistent across windows, but the\n",
            "                        model becomes less prone to getting stuck in a failure loop (default:\n",
            "                        True)\n",
            "  --fp16 FP16           whether to perform inference in fp16; True by default (default: True)\n",
            "  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n",
            "                        temperature to increase when falling back when the decoding fails to meet\n",
            "                        either of the thresholds below (default: 0.2)\n",
            "  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n",
            "                        if the gzip compression ratio is higher than this value, treat the\n",
            "                        decoding as failed (default: 2.4)\n",
            "  --logprob_threshold LOGPROB_THRESHOLD\n",
            "                        if the average log probability is lower than this value, treat the\n",
            "                        decoding as failed (default: -1.0)\n",
            "  --no_speech_threshold NO_SPEECH_THRESHOLD\n",
            "                        if the probability of the <|nospeech|> token is higher than this value AND\n",
            "                        the decoding has failed due to `logprob_threshold`, consider the segment\n",
            "                        as silence (default: 0.6)\n",
            "  --word_timestamps WORD_TIMESTAMPS\n",
            "                        (experimental) extract word-level timestamps and refine the results based\n",
            "                        on them (default: False)\n",
            "  --prepend_punctuations PREPEND_PUNCTUATIONS\n",
            "                        if word_timestamps is True, merge these punctuation symbols with the next\n",
            "                        word (default: \"'“¿([{-)\n",
            "  --append_punctuations APPEND_PUNCTUATIONS\n",
            "                        if word_timestamps is True, merge these punctuation symbols with the\n",
            "                        previous word (default: \"'.。,，!！?？:：”)]}、)\n",
            "  --highlight_words HIGHLIGHT_WORDS\n",
            "                        (requires --word_timestamps True) underline each word as it is spoken in\n",
            "                        srt and vtt (default: False)\n",
            "  --max_line_width MAX_LINE_WIDTH\n",
            "                        (requires --word_timestamps True) the maximum number of characters in a\n",
            "                        line before breaking the line (default: None)\n",
            "  --max_line_count MAX_LINE_COUNT\n",
            "                        (requires --word_timestamps True) the maximum number of lines in a segment\n",
            "                        (default: None)\n",
            "  --max_words_per_line MAX_WORDS_PER_LINE\n",
            "                        (requires --word_timestamps True, no effect with --max_line_width) the\n",
            "                        maximum number of words in a segment (default: None)\n",
            "  --threads THREADS     number of threads used by torch for CPU inference; supercedes\n",
            "                        MKL_NUM_THREADS/OMP_NUM_THREADS (default: 0)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}